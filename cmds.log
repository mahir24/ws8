  951  mkdir totalCount
  952  for i in $UNIQ_IDS; do      for j in 'cat $UNIQ_IDS.helpfulnessReviews.txt'; do          total=$(echo $total+$j | bc); ((count++));      done;       echo "total= $total, count= $count" > totalCount/$i.totalCount.txt;count=0;total=0;   done;
  953  for i in $UNIQ_IDS; do      for j in `cat $UNIQ_IDS.helpfulnessReviews.txt`; do          total=$(echo $total+$j | bc); ((count++));      done;       echo "total= $total, count= $count" > totalCount/$i.totalCount.txt;count=0;total=0;   done;
  954  ls
  955  cd totalCount
  956  ls
  957  cat 33993847.totalCount.txt
  958  cd ..
  959  rm -r totalCount
  960  mkdir totalCount
  961  total=0;count=0;
  962  for i in $UNIQ_IDS; do      for j in `cat $UNIQ_IDS.helpfulnessReviews.txt`; do          total=$(echo $total+$j | bc); ((count++));      done;       echo "total= $total, count= $count" > totalCount/$i.totalCount.txt;count=0;total=0;   done;
  963  cd totalCount
  964  w
  965  ls
  966  cat 33993847.totalCount.txt
  967  cat 51204643.totalCount.txt
  968  total=0; count=0;
  969  cd ..
  970  rm -r totalCount
  971  ls
  972  cat 33993847.helpfulnessReviews.txt
  973  cd ~/WS4
  974  ls
  975  cd CUSTOMERS
  976  ls
  977  cd ..
  978  cd PRODUCTS
  979  ls
  980  cat 0316666343.txt
  981  ls
  982  total=0;count=0;
  983  cd ..
  984  ls
  985  cat 0316666343.helpfulness.txt
  986  cd PRODUCTS
  987  0316666343.helpfulness.txt
  988  cat 0316666343.helpfulness.txt
  989  cd ~/A2
  990  ls
  991  cd PRODUCTS
  992  l
  993  sls
  994  l
  995  ls
  996  cat 0060193395.helpfulnessReviews.txt
  997  cd ..
  998  ls
  999  head -n 1 amazon_reviews_us_Books_v1_02.tsv
 1000  cd tempProducts
 1001  cd ..
 1002  UNIQ_IDS="$(awk '{print $2}' < productids.100.txt | sort | uniq)"
 1003  cd tempProducts
 1004  ls
 1005  cd ../PRODCUTS
 1006  cd ../PRODUCTS
 1007  ls
 1008  mkdir starRating
 1009  cd ../tempProducts
 1010  for i in $UNIQ_IDS; do cut -d "    " -f 8 $i.txt > ~/A2/PRODUCTS/starRating/$i.stars.txt; done
 1011  for i in $UNIQ_IDS; do cut -d "	" -f 8 $i.txt > ~/A2/PRODUCTS/starRating/$i.stars.txt; done
 1012  cd../PRODCUTS
 1013  cd../PRODUCTS
 1014  cd..
 1015  cd ../PRODUCTS
 1016  ls
 1017  cd starRating
 1018  ls
 1019  cat 0060193395.stars.txt
 1020  ls
 1021  for i in $UNIQ_IDS; do      for j in 'cat $UNIQ_IDS.stars.txt'; do          total=$(echo $total+$j | bc); ((count++));      done;       echo "total= $total, count= $count" > totalCount/$i.totalCount.txt;count=0;total=0;
 1022  mkdir totalCount
 1023  for i in $UNIQ_IDS; do      for j in 'cat $UNIQ_IDS.stars.txt'; do          total=$(echo $total+$j | bc); ((count++));      done;       echo "total= $total, count= $count" > totalCount/$i.totalCount.txt;count=0;total=0;   done;
 1024  for i in $UNIQ_IDS; do      for j in `cat $UNIQ_IDS.stars.txt`; do          total=$(echo $total+$j | bc); ((count++));      done;       echo "total= $total, count= $count" > totalCount/$i.totalCount.txt;count=0;total=0;   done;
 1025  ls
 1026  cd totalCount
 1027  ls
 1028  cat 0060193395.totalCount.txt
 1029  cat 014131088X.totalCount.txt
 1030  cat 0060514558.totalCount.txt
 1031  cat 0399142789.totalCount.txt
 1032  cat 0066214130.totalCount.txt
 1033  cd ..
 1034  rm -r starRating
 1035  cd totalCount
 1036  ls
 1037  cat 0156027321.totalCount.txt
 1038  cd ..
 1039  rm -r totalCount
 1040  ls
 1041  cat 0316011770.stars.txt
 1042  cat 0060193395.stars.txt
 1043  ls
 1044  echo $total
 1045  total=0;count=0;
 1046  ls
 1047  for i in `cat 0060193395.stars.txt` ; do total=$(echo $total+$i | bc); ((count++)); done;
 1048  echo $total $count
 1049  mkdir totalCount
 1050  for i in $UNIQ_IDS; do      for j in `cat $UNIQ_IDS.stars.txt`; do          total=$(echo $total+$j | bc); ((count++));      done;       echo "total= $total, count= $count" > totalCount/$i.totalCount.txt;count=0;total=0;   done;
 1051  cd totalCount
 1052  l
 1053  sls
 1054  ls
 1055  cat 0060193395.totalCount.txt
 1056  cat  0060761288.totalCount.txt
 1057  cd ..
 1058  rm totalCount
 1059  rm -r  totalCount
 1060  echo $total
 1061  echo $count
 1062  total=0;count=0;
 1063  for i in `cat 0060193395.stars.txt` ; do total=$(echo $total+$i | bc); ((count++)); done;
 1064  echo $total $count
 1065  cd ..
 1066  ls
 1067  cd ..
 1068  ls
 1069  UNIQ_IDS="$(awk '{print $2}' < productids.100.txt | sort | uniq)"
 1070  echo $UNIQ_IDS
 1071  cd PRODUCTS
 1072  cd starRating
 1073  ls
 1074  for i in $UNIQ_IDS; do      for j in `cat $UNIQ_IDS.stars.txt`; do          total=$(echo $total+$j | bc); ((count++));          echo "total= $total, count= $count" > totalCount/$i.totalCount.txt;      done;       count=0;total=0;   done;
 1075  ls
 1076  mkdir totalCount
 1077  for i in $UNIQ_IDS; do      for j in `cat $UNIQ_IDS.stars.txt`; do          total=$(echo $total+$j | bc); ((count++));          echo "total= $total, count= $count" > totalCount/$i.totalCount.txt;      done;       count=0;total=0;   done;
 1078  ls
 1079  cd totalCount
 1080  ls
 1081  cat 0060193395.totalCount.txt
 1082  cd ..
 1083  rm -r totalCount
 1084  total=0;count=0;
 1085  ls
 1086  mkdir totalCount
 1087  for i in $UNIQ_IDS; do      for j in `cat $UNIQ_IDS.stars.txt`; do          total=$(echo $total+$j | bc); ((count++));          echo "total= $total, count= $count" > totalCount/$i.totalCount.txt;      done;       count=0;total=0;   done;
 1088  ls
 1089  cd totalCount
 1090  ls
 1091  cat 0060193395.totalCount.txt
 1092  cd..
 1093  cd ..
 1094  for i in `cat 0060193395.stars.txt` ; do total=$(echo $total+$i | bc); ((count++)); done;
 1095  echo $total $count
 1096  total=0; count=0;
 1097  for i in `cat 0060193395.stars.txt` ; do total=$(echo $total+$i | bc); ((count++)); done;
 1098  echo $total $count
 1099  la
 1100  rm totalCount
 1101  rm -r totalCount
 1102  mkdirtotalCount
 1103  mkdir totalCount
 1104  total=0;count=0;
 1105  for i in $UNIQ_IDS; do     for j in `cat $UNIQ_IDS.stars.txt`; do         total=$(echo $total+$j | bc); ((count++));     done;     echo "total= $total, count= $count" > totalCount/$i.totalCount.txt;     count=0;total=0;   done;
 1106  ls
 1107  cd totalCout
 1108  cd totalCount
 1109  ls
 1110  cat 0060193395.totalCount.txt
 1111  cd ..
 1112  total=0;count=0;
 1113  for i in `cat 0060193395.stars.txt` ; do total=$(echo $total+$i | bc); ((count++)); done;
 1114  echo $total $count
 1115  tmux
 1116  ls
 1117  cd WS5
 1118  ls
 1119  cd tempCustomers
 1120  ls
 1121  cd ..
 1122  rm tempCustomers
 1123  rm -r  tempCustomers
 1124  UNIQ_IDS="$(awk '{print $2}' < customerids.1000.txt | sort | uniq)"
 1125  for i in {1..10}; do echo "$i"; done;
 1126  for i in $UNIQ_IDS; do egrep "	$i	" amazon_reviews_us_Books_v1_02.tsv > tempCustomers/$i.txt; echo "$i"; done;
 1127  ls
 1128  mkdir tempCustomers
 1129  ls
 1130  for i in $UNIQ_IDS; do egrep "	$i	" amazon_reviews_us_Books_v1_02.tsv > tempCustomers/$i.txt; echo "$i"; done;
 1131  ls
 1132  cd WS5
 1133  ls
 1134  cd tempCustomers
 1135  ls
 1136  cat UNIQ_IDS.txt
 1137  rm UNIQ_IDS.txt
 1138  ls
 1139  mkdir tempCustomers
 1140  for i in $UNIQ_IDS; do egrep "	$i	" amazon_reviews_us_Books_v1_02.tsv > tempCustomers/$i.txt; echo "$i" ; done;
 1141  UNIQ_IDS="$(awk '{print $2}' < customerids.1000.txt | sort | uniq)"
 1142  ls
 1143  cd tempCustomers
 1144  ls
 1145  cd ..
 1146  for i in $UNIQ_IDS; do egrep "	$i	" amazon_reviews_us_Books_v1_02.tsv > tempCustomers/$i.txt; echo "$i" ; done;
 1147  ls
 1148  cd tempCustomers
 1149  ls
 1150  w
 1151  cd ..
 1152  head -n 1 amazon_reviews_us_Books_v1_02.tsv
 1153  cd
 1154  ls
 1155  cd WS5
 1156  ls
 1157  mkdir CUSTOMERS
 1158  for i in $UNIQ_IDS; do cut -d "	" -f 13, 14, 15 $i.txt > ~/WS5/CUSTOMERS/$i.helpfulnessReviews.txt; done
 1159  echo $UNIQ_IDS
 1160  ls
 1161  cd CUSTOMERS
 1162  ls
 1163  cat 53063505.helpfulnessReviews.txt
 1164  cat 52974218.helpfulnessReviews.txt
 1165  cd ..
 1166  rm -r CUSTOMERS
 1167  ls
 1168  cd tempCustomers
 1169  ls
 1170  cat  53018444.txt
 1171  head -n 1 53018444.txt
 1172  cd ..
 1173  ls
 1174  mkdir CUSTOMERS
 1175  cd tempCustomers
 1176  ls
 1177  for i in $UNIQ_IDS; do cut -d "   " -f 13,14,15 $i.txt > ~/A2/CUSTOMERS/$i.Reviews.txt; done
 1178  cd ..
 1179  cd CUSTOMERS
 1180  w
 1181  l
 1182  ls
 1183  cd ..
 1184  cd tempCustomers
 1185  for i in $UNIQ_IDS; do cut -d "   " -f 13,14,15 $i.txt > ~/WS5/CUSTOMERS/$i.Reviews.txt; done
 1186  cd ../CUSTOMERS
 1187  ls
 1188  w
 1189  ls
 1190  rm customerids.1000.txt
 1191  head -1000 customerids.txt.sorted.uniqcount.reversed >customerids.1000.txt
 1192  ls
 1193  UNIQ_IDS="$(awk '{print $2}' < customerids.1000.txt | sort | uniq)"
 1194  tmux
 1195  ls
 1196  cd WS5
 1197  ls
 1198  cd tempCustomers
 1199  ls
 1200  cd .. 
 1201  rm -r tempCustomers
 1202  cat ws5.txt
 1203  em ws5.txt
 1204  rm ws5.txt
 1205  ls
 1206  history
 1207  script ws5.txt
 1208  history > cmds.log
 1209  ls
 1210  cat ws5.txt
 1211  ls
 1212  git init
 1213  perl -pe 's/\x1b\[[0-9;]*[mG]//g' ws5.txt > ws5.txt.clean
 1214  tr -cd '\11\12\15\40-\176' < ws5.txt.clean > ws5.txt.clean2
 1215  ls
 1216  git add ws5.txt.clean2 cmds.log
 1217  git status
 1218  git commit -m "Worksheet 5"
 1219  git remote add origin https://github.com/mahir24/ws5.git
 1220  git push -u origin master
 1221  cd ..
 1222  cd A2
 1223  ls
 1224  history
 1225  clear
 1226  ls
 1227  cd CUSTOMERS
 1228  ls
 1229  cd ..
 1230  ls
 1231  UNIQ_IDS="$(awk '{print $2}' < customerids.100.txt | sort | uniq)"
 1232  cd tempCustomers
 1233  ls
 1234  for i in $UNIQ_IDS; do cut -d "    " -f 8,9 $i.txt > ~/A2/CUSTOMERS/$i.helpfulnessReviews.txt; done
 1235  for i in $UNIQ_IDS; do cut -d "	" -f 8,9 $i.txt > ~/A2/CUSTOMERS/$i.helpfulnessReviews.txt; done
 1236  cd ../CUSTOMERS
 1237  ls
 1238  cd ..
 1239  rm -r CUSTOMERS
 1240  cd tempCustomers
 1241  for i in $UNIQ_IDS; do cut -d "	" -f 8,9 $i.txt > ~/A2/CUSTOMERS/$i.helpfulnessReviews.txt; done
 1242  cd ../CUSTOMERS
 1243  cd ..
 1244  mkdir CUSTOMERS
 1245  cd tempCustomers
 1246  for i in $UNIQ_IDS; do cut -d "	" -f 8,9 $i.txt > ~/A2/CUSTOMERS/$i.helpfulnessReviews.txt; done
 1247  cd ../CUSTOMRS
 1248  cd ../CUSTOMERS
 1249  ls
 1250  cd ..
 1251  ls
 1252  cd datamash-1.3
 1253  ls
 1254  for FILE in `ls `; do CORR=./datamash …. <$FILE` ; echo "$FILE $CORR" ; done
 1255  for FILE in ../CUSTOMERS/.helpfulnessReviews.txt; do CORR=./datamash …. <$FILE` ; echo "$FILE $CORR" ; done
 1256  for FILE in ../CUSTOMERS/.helpfulnessReviews.txt; do CORR=./datamash …. <$FILE ; echo "$FILE $CORR" ; done
 1257  for FILE in ../CUSTOMERS/*.helpfulnessReviews.txt; do CORR=./datamash …. <$FILE ; echo "$FILE $CORR" ; done
 1258  ls
 1259  for FILE in ../CUSTOMERS/*.helpfulnessReviews.txt; do CORR=./datamash …. <$FILE ; echo "$FILE $CORR" ; done
 1260  cd ..
 1261  ls
 1262  cd CUSTOMERS
 1263  ls
 1264  cd ..
 1265  cd datamash-1.3
 1266  ls
 1267  for FILE in ../CUSTOMERS/*.helpfulnessReviews.txt; do CORR=./datamash …. <$FILE ; echo "$FILE $CORR" ; done
 1268  for FILE in ~/A2/CUSTOMERS/*.helpfulnessReviews.txt; do CORR=./datamash …. <$FILE ; echo "$FILE $CORR" ; donefor FILE in ~/A2/CUSTOMERS/*.helpfulnessReviews.txt; do CORR=./datamash …. <$FILE ; echo "$FILE $CORR" ; donecmd
 1269  for FILE in ../CUSTOMERS/*.helpfulnessReviews.txt; do CORR=./datamash …. <$FILE' ; echo "$FILE $CORR" ; done
 1270  cd ..
 1271  cd CUSTOMERS
 1272  ls
 1273  for FILE in `ls `; do CORR=./datamash …. <$FILE` ; echo "$FILE $CORR" ; done
 1274  for FILE in `ls `; do CORR=./datamash …. <$FILE ; echo "$FILE $CORR" ; done
 1275  cd ..
 1276  ls
 1277  cd  datamash-1.3
 1278  ls
 1279  cd ..
 1280  history >cmds.log
 1281  git init
 1282  git add cmds.log
 1283  ls
 1284  git status
 1285  git commit -m "Assignment 2" 
 1286  git remote add origin https://github.com/mahir24/a2.git
 1287  git push -u origin master
 1288  color 4
 1289  color a
 1290  ls
 1291  cd A1
 1292  ls
 1293  cat cmds.log
 1294  cd ..
 1295  history
 1296  clear
 1297  history
 1298  clear
 1299  kaiya = 'u luv it thooooo'
 1300  kaiya='u luv it thooooo'
 1301  echo $kaiya
 1302  clear
 1303  echo $kaiya
 1304  clear
 1305  echo $kaiya
 1306  clear
 1307  echo $kaiya
 1308  clear
 1309  arnie='red pill brother yee haw'
 1310  clear
 1311  $arnie
 1312  arnie="red pill brother yee haw"
 1313  clear
 1314  echo $arnie
 1315  clear
 1316  $kaiya
 1317  echo $kaiya
 1318  clear
 1319  cd ../WS4
 1320  cp customerids.txt.sorted.uniqcount.reversed ../WS5
 1321  cd ../WS5
 1322  ls
 1323  head -1000 customerids.txt.sorted.uniqcount.reversed >customerids.1000.txt
 1324  wc customerids.1000.txt
 1325  UNIQ_IDS="$(awk '{print $2}' < customerids.1000.txt | sort | uniq)"
 1326  mkdir tempCustomers
 1327  cd ../WS4
 1328  cp amazon_reviews_us_Books_v1_02.tsv ../WS5
 1329  cd ../WS5
 1330  ls
 1331  for i in $UNIQ_IDS; do egrep "   $i       " amazon_reviews_us_Books_v1_02.tsv > tempCustomers/$i.txt;
 1332  for i in $UNIQ_IDS; do egrep "	$i	" amazon_reviews_us_Books_v1_02.tsv > tempCustomers/$i.txt;
 1333  for in in $UNIQ_IDS;do egrep "	$i	" amazon_reviews_us_Books_v1_02.tsv > tempCustomers/$i.txt; done;
 1334  ls
 1335  cd tempCustomers
 1336  ls
 1337  cd ..
 1338  for i in UNIQ_IDS; do egrep "	$i	" amazon_reviews_us_Books_v1_02.tsv > tempCustomers/$i.txt; done;
 1339  ls
 1340  tempCustomers
 1341  cd tempCustomers
 1342  ls
 1343  cat UNIQ_IDS.txt
 1344  cd ..
 1345  ls
 1346  for i in {1..10}; echo $i;done;
 1347  ls
 1348  mkdir WS5
 1349  ls
 1350  cd WS4
 1351  ls
 1352  cd ..
 1353  cd WS5
 1354  script ws5.txt
 1355  tmux ls
 1356  tmux attach -t 0
 1357  tmux ls
 1358  cal
 1359  ls
 1360  a1
 1361  cd A1
 1362  ls
 1363  sort cmds.log
 1364  sort -ro cmds.log
 1365  sort -ro cmds.log test
 1366  sort -ro cmds.log test.txt
 1367  sort -r -o cmds.log test.txt
 1368  ls >cmds.log
 1369  ls
 1370  cmds .log
 1371  cat cmds.log
 1372  cs ..
 1373  cd ..
 1374  vi
 1375  sort cmds.log &
 1376  cd A1
 1377  cd ..
 1378  ls
 1379  cd ws1
 1380  ls
 1381  cd ws1
 1382  ls
 1383  cd WS1
 1384  ls
 1385  cat cmds.log
 1386  sort cmds.log &
 1387  cd ..
 1388  ls
 1389  cd WS2
 1390  ls
 1391  cd ..
 1392  cp WS2 MT
 1393  cp -r WS2 MT
 1394  ls
 1395  cd MT
 1396  ls
 1397  ls ??
 1398  echo $home
 1399  echo $HOME
 1400  echo $PATH
 1401  echo $home
 1402  echo home
 1403  echo HOME
 1404  pwd
 1405  echo " \"UNIX\" "
 1406  ls ?.txt
 1407  touch a.txt
 1408  ls
 1409  ls ?.txt
 1410  find . -type f -name "?"  -print
 1411  find . -type f -name "?.*"  -print
 1412  find  / -type f -name "file?"  -print   2>/dev/null
 1413  find  / -type f -name "cmd?.log"  -print   2>/dev/null
 1414  find  / -type f -name "cmd?"  -print   2>/dev/null
 1415  find  / -type f -name "verified?"  -print   2>/dev/null
 1416  cd ..
 1417  cd A2
 1418  ls
 1419  cd PRODUCTS
 1420  ls
 1421  cp 0743222245.helpfulnessReviews.txt ~/WS6
 1422  cd ~/WS6
 1423  la
 1424  export DATETIME=`date "+%Y%m%d_%H%M%S"`
 1425  DATETIME=`date "+%Y%m%d_%H%M%S"`
 1426  export DATETIME=`date "+%Y%m%d_%H%M%S"`
 1427  echo $DATETIME
 1428  ls
 1429  cp 0743222245.helpfulnessReviews.txt 0743222245.helpfulnessReviews.$DATETIME.txt
 1430  ls
 1431  ln -s 0743222245.helpfulnessReviews.20211015_000440.txt 0743222245.LATEST.txt
 1432  l
 1433  cronfile
 1434  crontab cronfile
 1435  crontab WS6
 1436  crontab ~/WS6
 1437  vi cronfile
 1438  cat cronfile
 1439  crontab cronfile
 1440  cronttab -l
 1441  crontab -l
 1442  ls
 1443  l
 1444  ls
 1445  crontab -l
 1446  l
 1447  ls
 1448  vi cronfile
 1449  crontab -l
 1450  crontab cronfile
 1451  crontab -l
 1452  vi cronfile
 1453  crontab -l
 1454  crontab cronfile
 1455  crontab -l
 1456  l
 1457  cat 0743222245.AVERAGE.txt
 1458  script ws6.txt
 1459  history >cmds.log
 1460  cat cmds.log
 1461  perl -pe 's/\x1b\[[0-9;]*[mG]//g' a.txt > a.txt.clean
 1462  perl -pe 's/\x1b\[[0-9;]*[mG]//g' ws6.txt > ws6.txt.clean
 1463  tr -cd '\11\12\15\40-\176' < ws6.txt.clean > ws6.txt.clean2
 1464  ls
 1465  less ws6.txt.clean2
 1466  git init
 1467  ls
 1468  git add cmds.log ws6.txt.clean2
 1469  rm a.txt.clean a.txt
 1470  ls
 1471  git status
 1472  git commit -m "Worksheet 6"
 1473  git remote add origin https://github.com/mahir24/WS6.git
 1474  git push -u origin master
 1475  cd ..
 1476  cd A1
 1477  l
 1478  cd ..
 1479  cd A2
 1480  l
 1481  cp amazon_reviews_us_Books_v1_02.tsv ~/WS7
 1482  cd ~/WS7
 1483  l
 1484  head -1 amazon_reviews_us_Books_v1_02.tsv
 1485  awk '{print $14}' amazon_reviews_us_Books_v1_02.tsv > amazon_reviews_us_Books_v1_02.reviewbody.tsv
 1486  w  amazon_reviews_us_Books_v1_02.reviewbody.tsv
 1487  vi amazon_reviews_us_Books_v1_02.reviewbody.tsv
 1488  cat amazon_reviews_us_Books_v1_02.reviewbody.tsv
 1489  l
 1490  cat  amazon_reviews_us_Books_v1_02.tsv
 1491  rm amazon_reviews_us_Books_v1_02.reviewbody.tsv
 1492  head -1 amazon_reviews_us_Books_v1_02.reviewbody.tsv
 1493  l
 1494  head -1 amazon_reviews_us_Books_v1_02.tsv
 1495  awk {print $14} amazon_reviews_us_Books_v1_02.tsv > amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv
 1496  awk '{print $14}' amazon_reviews_us_Books_v1_02.tsv > amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv
 1497  sed -i 's/<[a-z][a-z] \/>//g' amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv
 1498  vi amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv
 1499  sed -i 's/<br_\/>//g" amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv
 1500  sed -i 's/<br_\/>//g' amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv
 1501  cat amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv
 1502  sed -i 's/<[a-zA-Z]\+ \/>//g' amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv
 1503  l
 1504  head -n 11 amazon_reviews_us_Books_v1_02.tsv > amazonReview.10lines.txt
 1505  cat amazonReview.10lines.txt
 1506  sed -i 's/<[a-zA-Z]\+ \/>//g' amazonReview.10lines.txt
 1507  cat amazonReview.10lines.txt
 1508  awk '{print $14}' amazonReview.10lines.txt > amazonReviewBody.10lines.txt
 1509  cat amazonReviewBody.10lines.txt
 1510  rm  amazonReviewBody.10lines.txt
 1511  sed -i 's/<br_\/>//g' amazonReview.10lines.txt
 1512  cat amazonReviewBody.10lines.txt
 1513  cat amazonReview.10lines.txt
 1514  sed -i 's/,//g' amazonReview.10lines.txt
 1515  cat amazonReview.10lines.txt
 1516  sed -i 's/.//g' amazonReview.10lines.txt
 1517  cat amazonReview.10lines.txt
 1518  rm amazonReview.10lines.txt
 1519  head -n 11 amazon_reviews_us_Books_v1_02.tsv > amazonReview.10lines.txt
 1520  sed -i 's/\.//g' amazonReview.10lines.txt
 1521  cat amazonReview.10lines.txt
 1522  sed -i 's/,//g' amazonReview.10lines.txt
 1523  cat amazonReview.10lines.txt
 1524  sed -i 's/\<\>//g' amazonReview.10lines.txt
 1525  vi amazonReview.10lines.txt
 1526  sed -i 's/\<if\>//g' amazonReview.10lines.txt
 1527  vi amazonReview.10lines.txt
 1528  sed -i 's/<br_\/>//g' amazonReview.10lines.txt
 1529  cat amazonReview.10lines.txt
 1530  sed -i 's/<br_\/>//g' amazonReview.10lines.txt
 1531  cat amazonReview.10lines.txt
 1532  sed -i 's/<[a-zA-Z]\+ \/>//g' amazonReview.10lines.txt
 1533  cat amazonReview.10lines.txt
 1534  history > cmds.log
 1535  script ws7.txt
 1536  cat cmds.og
 1537  cat cmds.log
 1538  git init
 1539  git add cmds.log
 1540  git add ws7.txt
 1541  git status
 1542  git commit -m "Worksheet 7"
 1543  git remote add origin https://github.com/mahir24/WS7.git
 1544  git push -u origin master
 1545  perl -pe 's/\x1b\[[0-9;]*[mG]//g' ws7.txt > ws7.txt.clean
 1546  tr -cd '\11\12\15\40-\176' < ws7.txt.clean > ws7.txt.clean2
 1547  gti add ws7.txt.clean2
 1548  git add ws7.txt.clean
 1549  git status
 1550  git push -u origin master
 1551  git status
 1552  git remote add origin https://github.com/mahir24/WS7.git
 1553  git push -u origin master
 1554  git status
 1555  git remote -v
 1556  git commit -m "Script Cleaned"
 1557  git push -u origin master
 1558  Updates were rejected because the remote contains work that you do
 1559  hint: not have locally. This is usually caused by another repository pushing
 1560  hint: to the same ref. You may want to first integrate the remote changes
 1561  hint: (e.g., 'git pull ...') before pushing again.
 1562  git push -f origin master
 1563  mkdir A3
 1564  cd A2
 1565  ls
 1566  tmux new -s A3
 1567  tmux ls
 1568  tmux attach
 1569  l
 1570  cd ..
 1571  cd A2
 1572  cp -r PRODUCTS ~/A3
 1573  cd ../A3
 1574  l
 1575  cd PRODUCTS
 1576  l
 1577  cat 0971453209.helpfulnessReviews.txt
 1578  l
 1579  cd ..
 1580  l
 1581  cs PRODUCTS
 1582  cd PRODCUTS
 1583  cd PRODUCTS
 1584  i=0
 1585  median=`sort -n -k 2 0971453209.helpfulnessReviews.txt | awk ' { a[i++]=$2; } END { print a[int(i/2)]; }'`
 1586  echo $i
 1587  median=`sort -n -k 2 1400046610.helpfulnessReviews.txt | awk ' { a[i++]=$2; } END { print a[int(i/2)]; }'`
 1588  echo $i
 1589  echo $median
 1590  awk -v median=$median '$2 < median {print $1,0} $2 >= median {print $1,1}' 0971453209.helpfulnessReviews.txt > 0971453209.helpfulnessReviews.BINARY.txt
 1591  head 0971453209.helpfulnessReviews.txt 0971453209.helpfulnessReviews.BINARY.txt
 1592  ls
 1593  cd PRODUCTS
 1594  mkdir BINARY
 1595  for i in ls |awk -v median=$median '$2 < median {print $1,0} $2 >= median {print $1,1}' $i > BINARY/$i.BINARY.txt; done;
 1596  for i in ls | awk -v median=$median '$2 < median {print $1,0} $2 >= median {print $1,1}' $i > BINARY/$i.BINARY.txt; done;
 1597  for i in ls awk -v median=$median '$2 < median {print $1,0} $2 >= median {print $1,1}' $i > BINARY/$i.BINARY.txt; done;
 1598  for i in ls awk -v median=$median '$2 < median {print $1,0} $2 >= median {print $1,1}' $i >> BINARY/$i.BINARY.txt; done;
 1599  for i in ls awk -v median=$median '$2 < median {print $1,0} $2 >= median {print $1,1}' $i > BINARY/$i.BINARY.txt; done
 1600  for i in ls echo $i
 1601  for i in ls echo $i; done;
 1602  for i in ls echo $i; done
 1603  for i in ls| echo $i| ; done
 1604  for i in ls echo $i; done
 1605  for i in ls echo $i;
 1606  for i in 'ls' echo $i; done;
 1607  for i in `ls| do echo $i; done;
 1608  for i in `ls; do echo $i; done;
 1609  for i in `ls; do echo $i; done
 1610  ;
 1611  for i in `ls; do echo $i; done;
 1612  for i in `ls`; do echo $i; done;
 1613  for i in `ls` awk -v median=$median '$2 < median {print $1,0} $2 >= median {print $1,1}' $i > BINARY/$i.BINARY.txt; done
 1614  for i in `ls`; do awk -v median=$median '$2 < median {print $1,0} $2 >= median {print $1,1}' $i > BINARY/$i.BINARY.txt; donefor i in `ls`; do awk -v median=$median '$2 < median {print $1,0} $2 >= median {print $1,1}' $i > BINARY/$i.BINARY.txt; done
 1615  cd BINARY
 1616  l
 1617  head 1400046610.helpfulnessReviews.txt.BINARY.txt
 1618  head 0895261901.helpfulnessReviews.txt.BINARY.txt
 1619  cd ..
 1620  rm -r BINARY
 1621  for i in `ls`; do median=`sort -n -k 2 1400046610.helpfulnessReviews.txt | awk ' { a[i++]=$2; } END { print a[int(i/2)]; }'` | awk -v median=$median '$2 < median {print $1,0} $2 >= median {print $1,1}' $i > BINARY/$i.BINARY.txt; done
 1622  l
 1623  mkdir BINARY
 1624  for i in `ls`; do median=`sort -n -k 2 1400046610.helpfulnessReviews.txt | awk ' { a[i++]=$2; } END { print a[int(i/2)]; }'` | awk -v median=$median '$2 < median {print $1,0} $2 >= median {print $1,1}' $i > BINARY/$i.BINARY.txt; done
 1625  cd BINARY
 1626  l
 1627  head 1576734587.helpfulnessReviews.txt.BINARY.txt
 1628  1400046610.helpfulnessReviews.txt.BINARY.txt
 1629  head 1400046610.helpfulnessReviews.txt.BINARY.txt
 1630  cd ..
 1631  rm -r BINARY
 1632  mkdir BINARY
 1633  for i in `ls`; do median=`sort -n -k 2 1400046610.helpfulnessReviews.txt | awk ' { a[i++]=$2; } END { print a[int(i/2)]; }'` | awk -v median=$median '$2 < median {print $1,0} $2 >= median {print $1,1}' $i > BINARY/$i.BINARY.txt| median=0; done
 1634  cd BINARY
 1635  l
 1636  head 1576734587.helpfulnessReviews.txt.BINARY.txt
 1637  head 0975599518.helpfulnessReviews.txt.BINARY.txt
 1638  echo $median
 1639  head 0743222245.helpfulnessReviews.txt.BINARY.txt
 1640  cd ..
 1641  rm -r BINARY
 1642  mkdir BINARY
 1643  for i in `ls`; do median=`sort -n -k 2 $i | awk ' { a[i++]=$2; } END { print a[int(i/2)]; }'` | awk -v median=$median '$2 < median {print $1,0} $2 >= median {print $1,1}' $i > BINARY/$i.BINARY.txt| median=0; done
 1644  cd BINARY
 1645  l
 1646  head 1594480001.helpfulnessReviews.txt.BINARY.txt
 1647  head 1576734587.helpfulnessReviews.txt.BINARY.txt
 1648  cd ..
 1649  l
 1650  head 0971453209.helpfulnessReviews.txt 0971453209.helpfulnessReviews.BINARY.txt
 1651  median=`sort -n -k 2 0971453209.helpfulnessReviews.txt | awk ' { a[i++]=$2; } END { print a[int(i/2)]; }'`
 1652  echo $median
 1653  rm -r BINARY
 1654  rm 0971453209.helpfulnessReviews.BINARY.txt
 1655  awk -v median=$median '$2 < median {print $1,0} $2 >= median {print $1,1}' 0971453209.helpfulnessReviews.txt > 0971453209.helpfulnessReviews.BINARY.txt
 1656  l
 1657  head 0971453209.helpfulnessReviews.txt 0971453209.helpfulnessReviews.BINARY.txt
 1658  mkdir BINARY
 1659  for i in `ls`; do median=`sort -n -k 2 $i | awk ' { a[i++]=$2; } END { print a[int(i/2)]; }'`; awk -v median=$median '$2 < median {print $1,0} $2 >= median {print $1,1}' $i > BINARY/$i.BINARY.txt| median=0; done
 1660  cd BINARY
 1661  l
 1662  head 1594480001.helpfulnessReviews.txt.BINARY.txt
 1663  head 1576734587.helpfulnessReviews.txt.BINARY.txt
 1664  head 1558743669.helpfulnessReviews.txt.BINARY.txt
 1665  head 1400046610.helpfulnessReviews.txt.BINARY.txt
 1666  cd ..
 1667  cd BINARY
 1668  cd /A3/PRODUCTS/BINARY
 1669  cd /A3/PRODUCTS/
 1670  cd A3
 1671  cd PRODUCTS
 1672  cd BINARY
 1673  ../datamesh/datamash  -W ppearson 1:2 < head 1400046610.helpfulnessReviews.txt.BINARY.txt
 1674  ../datamesh-1.3/datamash  -W ppearson 1:2 < head 1400046610.helpfulnessReviews.txt.BINARY.txt
 1675  ../datamesh-1.3/datamash  -W ppearson 1:2 < 1400046610.helpfulnessReviews.txt.BINARY.txt
 1676  cd ~A2
 1677  ls
 1678  cd ~/A2
 1679  ls
 1680  cp -r datamesh-1.3 A3
 1681  cd ~/A3/PRODUCTS
 1682  /BINARY
 1683  cd BINARY
 1684  ../datamash-1.3/datamash  -W ppearson 1:2 < 1400046610.helpfulnessReviews.txt.BINARY.txt
 1685  cd ~/A2
 1686  cp datamash-1.3 A3
 1687  cp -r datamash-1.3 A3
 1688  cd ~/A3
 1689  cd PRODUCS/BINARY
 1690  cd PRODUCTS/BINARY
 1691  l
 1692  ../datamash-1.3/datamash  -W ppearson 1:2 < 1400046610.helpfulnessReviews.txt.BINARY.txt
 1693  ./datamash-1.3/datamash  -W ppearson 1:2 < 1400046610.helpfulnessReviews.txt.BINARY.txt
 1694  cd ..
 1695  l
 1696  cd ..
 1697  l
 1698  ls
 1699  cd ~/A2
 1700  l
 1701  cd datamash-1.3
 1702  l
 1703  ./datamash  -W ppearson 1:2 < ~/A3/PRODUCTS/BINARY/1400046610.helpfulnessReviews.txt.BINARY.txt
 1704  for file in ~/A3/PRODUCTS/BINARY; do ./datamash -W ppearson 2:1 < ~/A3/PRODUCTS/BINARY/$file.corr;done
 1705  for file in ~/A3/PRODUCTS/BINARY; do ./datamash -W ppearson 2:1 < ~/A3/PRODUCTS/BINARY/$file > ~/A3/PRODUCTS/BINARY/$file.corr ; done
 1706  for file in ~/A3/PRODUCTS/BINARY; do ./datamash -W ppearson 2:1 < ~/A3/PRODUCTS/BINARY/$file; done
 1707  for file in `ls ~/A3/PRODUCTS/BINARY`; do ./datamash -W ppearson 2:1 < ~/A3/PRODUCTS/BINARY/$file > ~/A3/PRODUCTS/BINARY/$file.corr ; done
 1708  cd ~/A3/PRODUCTS/BINARY/
 1709  l
 1710  head 1594480001.helpfulnessReviews.txt.BINARY.txt.corr
 1711  *.helpfulnessReviews.txt.BINARY.txt.corr|sort -rn|head -1
 1712  head 0060193395.helpfulnessReviews.txt.BINARY.txt.corr
 1713  *.helpfulnessReviews.txt.BINARY.txt.corr | awk -F\. 'm<$NF{m=$NF;s=$0}END{print s}'
 1714  max_number=`ls *.helpfulnessReviews.txt.BINARY.txt.corr|sort -rn|head -1`
 1715  echo $max_number
 1716  head 1594480001.helpfulnessReviews.txt.BINARY.txt.corr
 1717  head 068484267X.helpfulnessReviews.txt.BINARY.txt.corr
 1718  ls *.helpfulnessReviews.txt.BINARY.txt.corr | sort -nrk1.12 | head -1
 1719  ls *.helpfulnessReviews.txt.BINARY.txt.corr | sort -nrk1.12 | head
 1720  head 1594480001.helpfulnessReviews.txt.BINARY.txt.corr
 1721  head 1594480001.helpfulnessReviews.txt.BINARY.txt.corr 1576734587.helpfulnessReviews.txt.BINARY.txt.corr 1558743669.helpfulnessReviews.txt.BINARY.txt.corr
 1722  head 0895261901.helpfulnessReviews.txt.BINARY.txt.corr
 1723  ls
 1724  sort 1594480001.helpfulnessReviews.txt.BINARY.txt
 1725  sort 1594480001.helpfulnessReviews.txt.BINARY.txt > 1594480001.BINARY.SORTED.txt
 1726  scp username@remote:/1594480001.BINARY.SORTED.txt  C:\Users\mahir\Desktop\CS 185C
 1727  scp username@remote:/1594480001.BINARY.SORTED.txt  C:\Users\mahir\Desktop\CS185C
 1728  scp rahman@f6linux20:/1594480001.BINARY.SORTED.txt  C:\Users\mahir\Desktop\CS185C
 1729  logout
 1730  exit
 1731  ls
 1732  cd CUSTOMERS
 1733  l
 1734  ls
 1735  cd ..
 1736  cp CUSTOMERS ~/A3
 1737  cp -r  CUSTOMERS ~/A3
 1738  cd ~/A3
 1739  ls
 1740  script a3.txt
 1741  script a3_part2.txt
 1742  exit
 1743  logout
 1744  pwd
 1745  cd ~/A3
 1746  cd PRODUCTS
 1747  cd BINARY
 1748  ls
 1749  scp rahman@12.42.205.182: /1594480001.BINARY.SORTED.txt C:\Users\mahir\Desktop\CS185C
 1750  ls
 1751  pws
 1752  pwd
 1753  ls
 1754  sftp
 1755  sort 1576734587.helpfulnessReviews.txt.BINARY.txt.corr > 1576734587.BINARY.SORTED.txt
 1756  sort 1576734587.helpfulnessReviews.txt.BINARY.txt > 1576734587.BINARY.SORTED.txt
 1757  cd ..
 1758  script a3_part3.txt
 1759  ls
 1760  cd ..
 1761  cd A1
 1762  l
 1763  cd ..
 1764  cd A2
 1765  l
 1766  cp amazon_reviews_us_Books_v1_02.tsv ~/A3
 1767  awkw -F "\t" '{print $14}' amazon_reviews_us_Books_v1_02.tsv | head -n 10 > amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv
 1768  awk -F "\t" '{print $14}' amazon_reviews_us_Books_v1_02.tsv | head -n 10 > amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv
 1769  rm  amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv
 1770  awk -F "\t" '{print $14}' amazon_reviews_us_Books_v1_02.tsv | head -n 10 > ~/A3/amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv
 1771  cd ~/A3
 1772  ls
 1773  rm amazon_reviews_us_Books_v1_02.tsv
 1774  cat amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv
 1775  cat amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv | sort | uniq -c
 1776  tr " " "\n" < amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv| sort| uniq -c | sort -n
 1777  tr " " "\n" < amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv| sort| uniq -c | sort -n -r
 1778  cat amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv
 1779  tr " " "\n" < amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv| sort| uniq -c | sort -n -r
 1780  sed -i 's/\?/>//g' amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv
 1781  sed -e 's/\?/>//g' amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv
 1782  sed -e 's/\<[a-zA-Z0-9]*[g|G]\>//g' input
 1783  sed -e 's/\<[?]\>//g' amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv
 1784  tr " " "\n" < amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv| sort| uniq -c | sort -n -r
 1785  sed -i 's/?//g' amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv
 1786  tr " " "\n" < amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv| sort| uniq -c | sort -n -r
 1787  sed 's/\<.\> \?//g' amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv
 1788  tr " " "\n" < amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv| sort| uniq -c | sort -n -r
 1789  sed 's/(?:\s\w\b|\b\w\s)//g' amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv
 1790  tr " " "\n" < amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv| sort| uniq -c | sort -n -r
 1791  sed 's/(?:\s\w\b|\b\w\s)//g' amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv
 1792  sed 's/\<.\> \?//g' amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv
 1793  cat  amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv
 1794  tr " " "\n" < amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv| sort| uniq -c | sort -n -r
 1795  tmux A3
 1796  cd A3
 1797  cd PRODUCTS
 1798  ls
 1799  cd starRating
 1800  cd ../BINARY
 1801  ls
 1802  cd ../starRating
 1803  for i in `ls`; do median=`sort -n -k 2 $i | awk ' { a[i++]=$2; } END { print a[int(i/2)]; }'` | awk -v median=$median '$2 < median {print $1,0} $2 >= median {print $1,1}' $i > starBINARY/$i.starBINARY.txt| median=0; done
 1804  mkdir starBINARY
 1805  for i in `ls`; do median=`sort -n -k 2 $i | awk ' { a[i++]=$2; } END { print a[int(i/2)]; }'` | awk -v median=$median '$2 < median {print $1,0} $2 >= median {print $1,1}' $i > starBINARY/$i.starBINARY.txt| median=0; done
 1806  cd starBINARY
 1807  ls
 1808  head 1594480001.stars.txt.starBINARY.txt
 1809  head 1576734587.stars.txt.starBINARY.txt
 1810  1558743669.stars.txt.starBINARY.txt
 1811  head 1558743669.stars.txt.starBINARY.txt
 1812  cd ..
 1813  ls
 1814  median=`sort -n -k 2 1594480001.stars.txt | awk ' { a[i++]=$; } END { print a[int(i/2)]; }'`
 1815  echo $median
 1816  head  1594480001.stars.txt
 1817  median=`sort -n -k  1594480001.stars.txt | awk ' { a[i++]=$2; } END { print a[int(i/2)]; }'`
 1818  cd ..
 1819  ls
 1820  head 1594480001.helpfulnessReviews.txt
 1821  cd starRating
 1822  median=`sort -n  1594480001.stars.txt | awk ' { a[i++]=$2; } END { print a[int(i/2)]; }'`
 1823  echo $median
 1824  pwd
 1825  ls
 1826  /home/rahman/A3/PRODUCTS/starRating1594480001.stars.txt1576734587.stars.txt
 1827  sort 1594480001.stars.txt
 1828  sort 1594480001.stars.txt > 1594480001.stars.SORTED.txt
 1829  tr " " "\n" < amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv| sort| uniq -c | sort -n -rtr " " "\n" < amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv| sort| uniq -c | sort -n -r
 1830  cd ..
 1831  ls
 1832  tr " " "\n" < amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv| sort| uniq -c | sort -n -r
 1833  sed 's/\<.\> \?//g' amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv
 1834  cat amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv
 1835  sed 's/\<.\> \?//g' amazon_reviews_us_Books_v1_02.REVIEWBODY.tsv > amazonReviews.sed.tsv
 1836  tr " " "\n" < amazonReviews.sed.tsv| sort| uniq -c | sort -n -r
 1837  54 the
 1838  tr " " "\n" < amazonReviews.sed.tsv| sort| uniq -c | sort -n -r | head -10 > 
 1839  cd ..
 1840  cd A3
 1841  git init 
 1842  perl -pe 's/\x1b\[[0-9;]*[mG]//g' a3.txt > a3.txt.clean
 1843  tr -cd '\11\12\15\40-\176' < a3.txt.clean > a3.txt.clean2
 1844  ls
 1845  perl -pe 's/\x1b\[[0-9;]*[mG]//g' a3_part2.txt > a3_part2.txt.clean
 1846  tr -cd '\11\12\15\40-\176' < a3_part2.txt.clean > a3_part2.txt.clean2
 1847  perl -pe 's/\x1b\[[0-9;]*[mG]//g' a3_part3.txt > a3_part3.txt.clean
 1848  tr -cd '\11\12\15\40-\176' < a3_part3.txt.clean > a3_part3.txt.clean2
 1849  git add a3_part3.txt.clean2 a3_part2.txt.clean2 a3.txt.clean2
 1850  git status
 1851  git commit -m "Assignment 3"
 1852  git remote add origin https://github.com/mahir24/a3.git
 1853  git push -u origin master
 1854  cd ../WS2
 1855  cp amazon_reviews_us_Books_v1_02.tsv ../WS8
 1856  cd ../WS8
 1857  head -1 amazon_reviews_us_Books_v1_02.tsv
 1858* 
 1859  head -1 amazon_reviews_us_Books_v1_02.tsv
 1860  awk -F"\t" '{print $12}' amazon_reviews_us_Books_v1_02.tsv > verifiedColumn.txt
 1861  grep Y verifiedColumn.txt > verified.txt
 1862  head -10  verified
 1863  head -10  verified.txt
 1864  grep N verifiedColumn.txt > unverified.txt
 1865  head -10  unverified.txt
 1866  head -100  verified.txt >> 100verified.txt
 1867  head -100  unverified.txt >> 100unverified.txt
 1868  wc 100verified.txt
 1869  awk -F"\t" '{print $12, $14}' amazon_reviews_us_Books_v1_02.tsv | head -100  > verified_Body.txt
 1870  cat verified_Body.txt
 1871  awk -F"\t" '{print $1}' verified_Body.txt
 1872  awk -F"\t" '{print $12}' verified_Body.txt
 1873  wc verified_Body.txt
 1874  grep Y verified_Body.txt > Yverified_Body.txt
 1875  cat Yverified_Body.txt
 1876  grep Y amazon_reviews_us_Books_v1_02.tsv | awk -F"\t" '{print $12, $14}' | head -100  > verified_Body.100.txt
 1877  cat verified_Body.100.txt
 1878  awk '/Y/{print $12,$14}' amazon_reviews_us_Books_v1_02.tsv| head -100  > 100verified_Body.txt
 1879  cat 100verified_Body.txt
 1880  ec 100verified_Body.txt
 1881  wc 100verified_Body.txt
 1882  wc verified_Body.100.txt
 1883  ls
 1884  wc Yverified_Body.txt
 1885  sed -i 's/.$/\t&/' verified_Body.100.txt
 1886  head -10 verified_Body.100.txt
 1887  sed -i 's/.$/\t&/' 100verified_Body.txt
 1888  head -10 100verified_Body.txt
 1889  rm 100verified_Body.txt
 1890  l
 1891  head -10 100verified.txt
 1892  rm 100verified.txt 100unverified.txt
 1893  sed -i 's/.$/\t&/' Yverified_Body.txt
 1894  head -10 Yverified_Body.txt
 1895  sed 's/.$/\t&/' Yverified_Body.txt
 1896  sed 's/.$/\t&/' Yverified_Body.txt | head -5
 1897  column -t -s $'\t' -n  Yverified_Body.txt
 1898  column -t -s $'\t' -n  Yverified_Body.txt | head -5
 1899  l
 1900  column -t -s $'\t' -n  verified_Body.100.txt | head -5
 1901  ls
 1902  awk '/Y/{print $12,$14}' verified_Body.100.txt| head -10
 1903  awk '/Y/{print $1}' verified_Body.100.txt| head -10
 1904  awk '{print $1}' verified_Body.100.txt| head -10
 1905  awk '{print $1}' vlerified_Body.100.txt| head -10
 1906  l
 1907  awk '{print $1}' Yverified_Body.txt| head -10
 1908  awk '{print $1}' verified_Body.txt| head -10
 1909  rm verified_Body.100.txt Yverified_Body.txt
 1910  rm Yverified_Body.txt
 1911  ls
 1912  l
 1913  awk '/Y/{print $1}' verified_Body.txt| head -10
 1914  awk '$1 ==  Y' verified_Body.txt| head -10
 1915  awk '$1 ==  'Y'' verified_Body.txt| head -10
 1916  awk '{print $1 == 'Y'}' verified_Body.100.txt| head -10
 1917  awk '{print $1 == 'Y'}' verified_Body.txt| head -10
 1918  awk '{print $1 == Y}' verified_Body.txt| head -10
 1919  awk '{print $1}' verified_Body.txt| head -10
 1920  head -10 verified_Body.txt 
 1921  grep Y verified_Body.txt | head -10
 1922  awk '{print $1}' verified_Body.txt| head -10
 1923  awk '{print $2}' verified_Body.txt| head -10
 1924  awk '{print $3}' verified_Body.txt| head -10
 1925  awk '{print $4}' verified_Body.txt| head -10
 1926  awk -F '$1 == Y' verified_Body.txt| head -10
 1927  awk -F '($1 == "Y")' {print} verified_Body.txt| head -10
 1928  awk -F "\t" '($12 == "Y") {print}' verified_Body.txt| head -10
 1929  awk -F "\t" '($1 == "Y") {print}' verified_Body.txt| head -10
 1930  awk -F "\t" '($1 == "Y") {print}' amazon_reviews_us_Books_v1_02.tsv| head -10
 1931  awk -F "\t" '($1 == "Y") {print $1}' amazon_reviews_us_Books_v1_02.tsv| head -10
 1932  awk -F "\t" '($1 == "Y") {print $1}' verified_Body.txt| head -10
 1933  awk -F "\t" '($1 == "Y") {print $1}' verified_Body.txt
 1934  awk -F "\t" '($1 == "Y") {print $2}' verified_Body.txt
 1935  awk -F "\t" '($12 == "Y") {print}' verified_Body.txt
 1936  awk -F "\t" '($12 == "Y") {print}' amazon_reviews_us_Books_v1_02.tsv 
 1937  awk -F "\t" '($1 == "Y") {print}' verified_Body.txt
 1938  awk -F "\t" '($12 == "Y") {print $14}' amazon_reviews_us_Books_v1_02.tsv | head -10
 1939  awk -F "\t" '($12 == "Y") {print $12, $14}' amazon_reviews_us_Books_v1_02.tsv | head -5
 1940  l
 1941  awk -F "\t" '($12 == "Y") {print $14}' amazon_reviews_us_Books_v1_02.tsv | head -100 > verified_body.100.txt
 1942  awk -F "\t" '($12 == "N") {print $14}' amazon_reviews_us_Books_v1_02.tsv | head -100 > unverified_body.100.txt
 1943  echo "Ready?"
 1944  sort verified_body.100.txt | uniq -c | sort -rn | head -n 10
 1945  tr " " "\n" < verified_body.100.txt | sort | uniq -c | sort -nr | head -10
 1946  tr " " "\n" < verified_body.100.txt | sort | uniq -c | sort -nr | head -10 | less
 1947  tr " " "\n" < verified_body.100.txt | sort | uniq -c | sort -nr | head -20
 1948  tr " " "\n" < unverified_body.100.txt | sort | uniq -c | sort -nr | head -10
 1949  tr " " "\n" < unverified_body.100.txt | sort | uniq -c | sort -nr | head -20
 1950  history > cmds.log
